---
title: "task01"
author: "Yirun Wang"
date: "16/08/2020"
output: html_document
---

```{r, message=FALSE}
library(tidyverse)
library(naniar)
library(data.table)
library(ggplot2)
library(ggmosaic)
library(readr)
```

## 0. Read in datasets
```{r}
transac <- fread("QVI_transaction_data.csv")
customer <- fread("QVI_purchase_behaviour.csv")

# head(transac)
```



# TRANSACTION DATASET

## 1. EDA

### 1.1 Data Structures
```{r}
# transac -> date objects
transac$DATE <- as.Date(transac$DATE, origin = "1899-12-30")
```

### 1.2 Text Analysis: Are these products all chips?
```{r}
# explore the digits and special chars
prod_words <- data.table(unlist(strsplit(unique(transac[, PROD_NAME]), "")))
setnames(prod_words, 'words')


# remove digits and special chars
prods <- gsub("[[:punct:]]", "", transac$PROD_NAME)
prods <- gsub('[0-9]+', "", prods)

transac <- transac %>% 
  mutate(`prodname` = prods)

# sort by freq
chip_rank <- sort(table(prods), decreasing = TRUE)
```

### 1.3 Remove salsa
```{r}
transac <- transac %>% 
  mutate(`SALSA` = grepl("salsa", tolower(prodname)))

transac <- transac[which(transac$`SALSA` == FALSE),]

to_drop <- c("SALSA")
transac <- transac[, !(names(transac) %in% to_drop)]
```

### 1.4 Initial Summary: Check for nulls and outliers

No missing vals.

Outliers
- 200 packs of chips were purchased in a single transaction
- 650 total sales (occurred in the same transaction)

```{r}
## missingness (NB: uncomment next line to run the code - takes a while)
# vis_miss(transac, warn_large_data = FALSE)

# outliers
transac %>% 
  select_if(is.numeric) %>% 
  pivot_longer(c(PROD_QTY, TOT_SALES), names_to = "variable", values_to = "value") %>% 
  ggplot(aes(value), x = variable) +
  facet_wrap(~ variable, scales = "free") +
  geom_boxplot() +
  theme_bw(base_size = 18) +
  theme(strip.text.x = element_text(size = 8))

# max(transac$PROD_QTY)

# summary: means and medians
# transac %>% 
#   select_if(is.numeric) %>% 
#   pivot_longer(c(PROD_QTY, TOT_SALES), names_to = "variable", values_to = "value") %>% 
#   group_by(variable) %>%
#   summarise(mean = mean(value, na.rm = TRUE), median = median(value, na.rm = TRUE))
```

### 1.5.1 Filter the dataset: Pinpoint the transaction of interest

Two instances in which 200 packs of chips were purchased in one go.
- same customer (same loyalty #)
- same store
- same type of chips
- different dates (autumn and winter)

```{r}
transac %>% 
  filter(PROD_QTY == max(PROD_QTY))

# transac %>% 
#   filter(TOT_SALES == max(TOT_SALES))
```

### 1.5.2 Filter the dataset: Pinpoint the customer of interest

The customer has had no other recorded transactions. Chips may be purchased for commercial purposes.
Remove this cusomer as it does not yield insights into behaviour.

```{r}
transac %>% 
  filter(LYLTY_CARD_NBR == "226000")
```

### 1.6 Remove outliers

```{r}
transac <- transac[!transac$LYLTY_CARD_NBR == "226000", ]

# re-examine the dataset
# max(transac$PROD_QTY)
```

### 1.7 Count the number of transactions by date

Only 364 dates -> one day missing.

```{r}
transac_date <- transac %>% 
  group_by(DATE) %>% 
  summarise(freq = n())
```

### 1.8 Fill in the missing date
```{r}
# Create a sequence of unique dates from 1/7/18 to 30/6/19
unique_dates <- list(DATE = seq(as.Date('2018-07-01'), as.Date('2019-06-30'), by=1))
# class(unique_dates)

transac_yearly = merge(x=transac_date, y=unique_dates, by="DATE", all.y = TRUE)

# replace NA with 0
# transac_yearly <- transac_yearly %>% 
#   mutate_if(is.integer, ~replace(., is.na(.), 0))
```

### 1.9 Plot transactions over time
```{r}
# call theme_bw first ow previous settings changed

fig1 <- transac_yearly %>% 
  ggplot(aes(x = DATE, y = freq)) +
  geom_line() +
  labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
  scale_x_date(breaks = "1 month") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, vjust = 0.5))

fig1
```

### 2.0 December transactions

Increase -> ZERO on Xmas day due to the public holiday closure -> Decrease.

```{r}
fig2 <- transac_yearly[months(transac_yearly$DATE) %in% month.name[12],] %>% 
  ggplot(aes(x = DATE, y = freq)) +
  geom_line() +
  labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, vjust = 0.5))

fig2
```


## 2. Pack Size

### 2.1 Extract the digits
```{r}
# !!! parse_number

transac <- transac %>% 
  mutate(`PACK SIZE` = parse_number(PROD_NAME))

# Check outputs
c(max(transac$`PACK SIZE`), min(transac$`PACK SIZE`))
```

### 2.2 Plot pack size
```{r}
transac_pack <- transac %>% 
  group_by(`PACK SIZE`) %>% 
  summarise(freq = n())

# max(transac_pack$freq)

fig3 <- transac_pack %>% 
  ggplot(aes(x=`PACK SIZE`, y=freq)) +
  geom_bar(stat = "identity") +
  labs(x = "Pack Size", y = "Number of transactions", title = "Transactions by pack size") +
  theme_bw()

fig3
```

## 3. Brands

### 3.1 Create brand names
```{r}
# Extract the first words of prod_name - regex
transac$BRAND <- gsub("([A-Za-z]+).*", "\\1", transac$PROD_NAME)

# Check reasonableness of results
unique(transac$BRAND)
```

### 3.2 Clean brand names
```{r}
# RRD & RED
transac$BRAND[which(transac$BRAND == "RRD")] = "Red"

# Check other brands
unique(transac$BRAND)
```

### 3.3 Repeat 3.2 on other brand adjustments
```{r}
# Natural & NCC
transac$BRAND[which(transac$BRAND == "NCC")] = "Natural"

# Snbts & Sunbites
transac$BRAND[which(transac$BRAND == "Snbts")] = "Sunbites"

# Infzns & Infuzions
transac$BRAND[which(transac$BRAND == "Infzns")] = "Infuzions"

# Smith & Smiths
transac$BRAND[which(transac$BRAND == "Smith")] = "Smiths"

# Grain & GrnWves
transac$BRAND[which(transac$BRAND == "GrnWves")] = "Grain"

# Doritos & Dorito
transac$BRAND[which(transac$BRAND == "Dorito")] = "Doritos"

# WW & Woolworths (NOTE1: CANT BE 100% SURE WITHOUT METADATA)
transac$BRAND[which(transac$BRAND == "WW")] = "Woolworths"

# Check results
unique(transac$BRAND)

```



# CUSTOMER DATASET

## 1. Tidying up the dataset: Missingness, Outliers

No missing values.
No outliers because no numeric data.

```{r}
# missingness
# vis_miss(customer, warn_large_data = FALSE)
```

## 2.1 Customers by lifestage

```{r}
# unique(customer$LIFESTAGE)
# unique(customer$PREMIUM_CUSTOMER)

lifestage <- customer %>% 
  group_by(LIFESTAGE) %>% 
  summarise(freq = n())

fig4 <- lifestage %>% 
  ggplot(aes(x=LIFESTAGE, y=freq)) +
  geom_bar(stat = "identity") +
  labs(x = "Lifestage", y = "Number of customers", title = "Customers by lifestage") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

fig4
```

## 2.2 Customers by premiumness
```{r}
premium <- customer %>% 
  group_by(PREMIUM_CUSTOMER) %>% 
  summarise(freq = n())

fig5 <- premium %>% 
  ggplot(aes(x=PREMIUM_CUSTOMER, y=freq)) +
  geom_bar(stat = "identity") +
  labs(x = "Customer Type", y = "Number of customers", title = "Customers by premiumness") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

fig5
```


# MERGE TRANSACTION TO CUSTOMER
```{r}
dat <- merge(transac, customer, all.x = TRUE)
dat
```




# WORK ON ONE DATASET 'dat' FROM HERE ONWARDS

## 0. Check for nulls

No nulls. (Uncomment the code as it takes a while to run)

```{r}
# vis_miss(dat, warn_large_data = FALSE)
```


## 1. Task02 Prep: Export dat as csv

Commented the code as it needed to be exported once only.

```{r}
# fwrite(dat, "QVI_data.csv")
```



# DATA ANALYSIS on CUSTOMER

## 1. Who spends the most on chips (total sales), describing customers by lifestage and how premium their general purchasing behaviour is - Which customer segment contribute most to chip sales?

Mainstream young customers & Budget older customers.
```{r}
# customer_lifeprem
```

```{r fig.width=10, fig.align="center"}
# Total sales by LIFESTAGE and PREMIUM_CUSTOMER
customer_lifeprem <- dat %>% 
  mutate(SEGMENT = paste(LIFESTAGE, PREMIUM_CUSTOMER)) %>% 
  select(TOT_SALES, SEGMENT) %>% 
  group_by(SEGMENT) %>% 
  summarise(TOTAL = sum(TOT_SALES)) %>% 
  arrange(desc(TOTAL))

# Plot
fig6 <- customer_lifeprem %>% 
  ggplot(aes(x=SEGMENT, y=TOTAL)) +
  geom_bar(stat = "identity") +
  labs(x = "Customer Segment", y = "Total Sales", title = "Total sales by lifestage and premiumness") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

fig6
```

## 1.1 Average number of units per customer

Older & young families.

```{r fig.width=10, fig.align="center"}
# Average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
unit_pc <- dat %>% 
  mutate(SEGMENT = paste(LIFESTAGE, PREMIUM_CUSTOMER)) %>% 
  select(PROD_QTY, SEGMENT) %>% 
  group_by(SEGMENT) %>% 
  summarise(AVERAGE = mean(PROD_QTY)) %>% 
  arrange(desc(AVERAGE))

# Plot
fig7 <- unit_pc %>% 
  ggplot(aes(x=SEGMENT, y=AVERAGE)) +
  geom_bar(stat="identity") +
  labs(x = "Customer Segment", y = "Number of units", title = "Number of units per customer by lifestage and premiumness") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

fig7

```

## 1.3 Average price per unit chips

Mainstream young and midage singles/couples paid the highest per unit price for chips. Premium customers more likely buy healthy alternatives, so consume less chips.

The price differences are not large. -> Check if statistially significant.

```{r fig.width=10, fig.align="center"}
price_pu <- dat %>% 
  mutate(SEGMENT = paste(LIFESTAGE, PREMIUM_CUSTOMER), UNIT_PRICE = TOT_SALES/PROD_QTY) %>% 
  select(UNIT_PRICE, SEGMENT) %>% 
  group_by(SEGMENT) %>% 
  summarise(AVG_PRICE = mean(UNIT_PRICE)) %>% 
  arrange(desc(AVG_PRICE))

# Plot
fig8 <- price_pu %>% 
  ggplot(aes(x=SEGMENT, y=AVG_PRICE)) +
  geom_bar(stat="identity") +
  labs(x = "Customer Segment", y = "Price per unit", title = "Average price per unit chips by lifestage and premiumness") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

fig8

```

## 1.4 t-test between average price perunit for mainstream vs premium and budget midage and young singles/couples

Two-sample t-test.
- select midage and young singles/couples
- mainstream vs premium + budget

The t-test results in a p-value of 0.81. As the p-value is large, there is no evidence that suggests there is a difference in average price per unit. In other words, the unit price for mainstream, young and midage singles/couples are not significantly higher than that of budget & premium young and midage singles/couples.

```{r}
# unique(price_pu$SEGMENT)

# Two samples: young and midage
young <- price_pu %>% 
  filter(SEGMENT %in% c("YOUNG SINGLES/COUPLES Mainstream", "YOUNG SINGLES/COUPLES Premium", "YOUNG SINGLES/COUPLES Budget"))

midage <- price_pu %>% 
  filter(SEGMENT %in% c("MIDAGE SINGLES/COUPLES Mainstream", "MIDAGE SINGLES/COUPLES Premium", "MIDAGE SINGLES/COUPLES Budget"))


# t-test
t.test(young$AVG_PRICE, midage$AVG_PRICE, alternative = "two.sided")

```


## 2. Mainstream young singles/couples - Do they tend to buy a particular brand of chips.

```{r fig.align="center"}
brand_midyoung <- dat %>% 
  mutate(SEGMENT = paste(LIFESTAGE, PREMIUM_CUSTOMER)) %>% 
  select(SEGMENT, BRAND)

```




